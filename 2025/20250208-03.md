---
title: "手把手教你本地部署Deepseek，开启AI自由探索之旅"
date: 2025-02-08 17:18:42
draft: false
categories: ["AI"]
tags: ["DeepSeek"]
cover: https://cdn.jsdelivr.net/gh/ueYao/image-hosting@main/blog/2025/02/20250210004236559040.png
---

## 一、本地部署前的准备工作

### 1. 硬件要求

Deepseek 的不同版本对硬件要求不同，以下为推荐配置：

|模型版本|CPU|GPU|内存|存储|
| ------------------| --------------------------------| -------------------------------| --------| -------|
|DeepSeek-R1-1.5B|4 核以上，Intel/AMD 多核处理器|可选 4GB+ 显存（如 GTX 1650）|8GB+|3GB+|
|DeepSeek-R1-7B|8 核以上，现代多核 CPU|8GB+ 显存（如 RTX 3070/4060）|16GB+|8GB+|
|DeepSeek-R1-14B|12 核以上|16GB+ 显存（如 RTX 4090）|32GB+|15GB+|
|DeepSeek-R1-32B|16 核以上（如 Ryzen 9 / i9）|24GB+ 显存（如 A100 40GB）|64GB+|30GB+|
|DeepSeek-R1-70B|32 核以上（服务器级 CPU）|多卡并行（如 2x A100 80GB）|128GB+|70GB+|

### 2. 软件环境

* **操作系统**：推荐 Windows、Linux（Ubuntu、CentOS）以获得最佳兼容性。
* **必备工具**：

  * 安装 Ollama（用于管理和运行 Deepseek）：[Ollama 官网](https://ollama.ai/)

## 二、本地部署步骤

### 1. 安装 Ollama

* **Windows**：下载 .msi 安装包，按照向导完成安装。
* **macOS**：下载 .dmg 安装包，将 Ollama 拖入 "Applications" 目录。
* **Linux**：使用终端执行 `curl -sSL https://ollama.ai/install.sh | sh`​​。
* **验证安装**：运行 `ollama --version`​​ 确认 Ollama 安装成功。

  ​![tmplqc_](https://cdn.jsdelivr.net/gh/ueYao/image-hosting@main/blog/2025/02/20250210004311970536.png)​

### 2. 下载并运行 Deepseek 模型

​![tmp9kp5wfdk.png](https://cdn.jsdelivr.net/gh/ueYao/image-hosting@main/blog/2025/02/20250210004336852240.png)​

1. 选择合适的模型版本，例如 `ollama run deepseek-r1:7b`​​。

    ​![tmpnlv6vds3.png](https://cdn.jsdelivr.net/gh/ueYao/image-hosting@main/blog/2025/02/20250210004411840559.png)​
2. 配置参数，如温度（控制生成随机性）、最大生成长度、Top-p 采样等。
3. 启动模型并开始交互。

    ​![tmp_](https://cdn.jsdelivr.net/gh/ueYao/image-hosting@main/blog/2025/02/20250210004437337149.png)​

### 3. 安装可视化界面（可选）

**Chatbox AI** 提供直观的 GUI，便于用户与模型交互。

​![tmpke8q8fls.png](https://cdn.jsdelivr.net/gh/ueYao/image-hosting@main/blog/2025/02/20250210004457933523.png)​

* **下载安装**：[Chatbox AI 官网](https://chatboxai.app/zh)

  ​![tmplo0n1qed.png](https://cdn.jsdelivr.net/gh/ueYao/image-hosting@main/blog/2025/02/20250210004520601261.png)​
* **连接本地模型**：在 "设置" 中选择 "Ollama API"，即可开始使用。

  ​![tmpa8wkfv7h.png](https://cdn.jsdelivr.net/gh/ueYao/image-hosting@main/blog/2025/02/20250210004539631808.png)​

  ‍

  ​![tmpg3jjcsli.png](https://cdn.jsdelivr.net/gh/ueYao/image-hosting@main/blog/2025/02/20250210004608674285.png)​

---

通过本地部署 Deepseek，用户不仅能够享受更高的安全性、稳定性和定制化能力，还能最大化发挥 AI 模型的潜力，助力各行业迈向智能化未来。

‍
